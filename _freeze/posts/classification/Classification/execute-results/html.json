{
  "hash": "7c95eb7cd10a3dbda8b282ecb79a1655",
  "result": {
    "markdown": "---\ntitle: What is Classification?\n---\n\nClassification is assigning some label to an input value based on some predictor variables. These labels are predefined and predictions are made based on previous predictions on similar data. There are various classifcation techniques such as Naive Bayes, K-Nearest-Neighbors, Logistic Regression, SVMs, etc. The most simple form of classification is Binary Classification, where one of two labels can be chosen from. Some use cases are image classification, spam filtering, or even medical diagnosis. One tough part with classification is especially with supervised learning techniques, the data has to be labeled into the categories which requires manual effort.\n\n\n### SMS Spam Dataset ###\nWe will use an SMS Spam dataset from Kaggle to determine if a message is spam or not. We will use different techniques to determine whether there is spam in a message.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\ndf = pd.read_csv('spam.csv', encoding='ISO-8859-1')\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5572</td>\n      <td>5572</td>\n      <td>50</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5169</td>\n      <td>43</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n      <td>MK17 92H. 450Ppw 16\"</td>\n      <td>GNT:-)\"</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4825</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Cleaning ###\nThis dataset needs a lot of cleaning. Ham: 0, Spam: 1.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\ndf = df.rename(columns={\"v1\":\"label\", \"v2\":\"sms\"})\ndf['label'] = df['label'].map({'ham':0, 'spam':1})\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>sms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf.drop_duplicates(inplace=True)\n```\n:::\n\n\nVisualization the lengths of the messages and different types of words can help us determine their correct classification\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf[\"len\"] = df[\"sms\"].apply(len)\ndf['len'].plot(bins=50, kind='hist')\nplt.ylabel(\"Count\")\nplt.ylabel(\"Num chars\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-5-output-1.png){width=601 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf.hist(column='len', by='label', bins=50)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\narray([<Axes: title={'center': '0'}>, <Axes: title={'center': '1'}>],\n      dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-6-output-2.png){width=600 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom wordcloud import WordCloud\nwc = WordCloud()\nhamWords = wc.generate(df[df['label'] == 0]['sms'].str.cat(sep=\" \"))\nplt.imshow(hamWords)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<matplotlib.image.AxesImage at 0x295a5656810>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-7-output-2.png){width=575 height=306}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nspamWords = wc.generate(df[df['label'] == 1]['sms'].str.cat(sep=\" \"))\nplt.imshow(spamWords)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n<matplotlib.image.AxesImage at 0x295a5672610>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-8-output-2.png){width=575 height=306}\n:::\n:::\n\n\n### Preprocessing ###\nPreprocessing is a huge process before text classification. We need to figure out a way to remove common words (stopwords) so they don't affect our model. We also need to develop some system for our classification purposes. NLTK library is commonly used for this.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport nltk\nimport re\nnltk.download(\"stopwords\")   \nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Kaustubh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ncorpus = []\nlabels = []\nfor i in range(0, len(df)):\n    try:\n        cleaned = re.sub('^[a-zA-Z]',' ', df['sms'][i])\n        cleaned = cleaned.lower()\n        cleaned.split()\n        cleaned=[ps.stem(cleaned) for word in cleaned if not word in stopwords.words('english')]\n        cleaned = ''.join(cleaned)\n        corpus.append(cleaned)\n        labels.append(df['label'][i])\n    except KeyError as err:\n        continue\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()\nX=cv.fit_transform(corpus).toarray()\nY=labels\nX\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2)\n```\n:::\n\n\n### Naive Bayes Method ###\nThis method uses Bayes Theorem and considers that features are independent of each other. It will consider the individual words in an sms independent and determine the probability of spam/ham using the classic Bayes Theorem formula.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(xTrain, yTrain)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nyPred = nb.predict(xTest)\nfrom sklearn.metrics import classification_report\nprint(classification_report(yTest, yPred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94       849\n           1       0.57      0.88      0.69       115\n\n    accuracy                           0.91       964\n   macro avg       0.77      0.89      0.82       964\nweighted avg       0.93      0.91      0.91       964\n\n```\n:::\n:::\n\n\nWe can see Naive Bayes gave us a 0.91 accuracy score\n\n### Logistic Regression Classification ###\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter=500)\nlr.fit(xTrain, yTrain)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nyPred = lr.predict(xTest)\nprint(classification_report(yTest, yPred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99       849\n           1       0.94      0.86      0.90       115\n\n    accuracy                           0.98       964\n   macro avg       0.96      0.93      0.94       964\nweighted avg       0.98      0.98      0.98       964\n\n```\n:::\n:::\n\n\nWe got a slightly higher accuracy with the LogisticRegression model\n\n### SVM Classifier ###\nThis classifier works by setting a hyperplane of some features and dividng the data into two sides of the hyperplane. One side will be classified as spam and the other as ham. SVM is computationally expensive but works well on smaller datasets.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn import svm\nsvc = svm.SVC()\nsvc.fit(xTrain, yTrain)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nyPred = svc.predict(xTest)\nprint(classification_report(yTest, yPred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       849\n           1       0.99      0.81      0.89       115\n\n    accuracy                           0.98       964\n   macro avg       0.98      0.90      0.94       964\nweighted avg       0.98      0.98      0.98       964\n\n```\n:::\n:::\n\n\nThe SVM classifier also gave a good accuracy\n\n",
    "supporting": [
      "Classification_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}